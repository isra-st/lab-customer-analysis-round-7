{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats, HTML\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib_inline \n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import colors as mcolors\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# a lot of different scaler to try\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "# a lot of different regression models to try\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, RANSACRegressor\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "\n",
    "# more regression models\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating Plots\n",
    "# default styles\n",
    "def set_sns_format(width=14, height=8):\n",
    "    sns.set_theme(palette='pastel', context='notebook',rc={'savefig.dpi':300})\n",
    "    matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "    matplotlib.rcParams['figure.figsize'] = (width, height)\n",
    "    return None\n",
    "set_sns_format(width=14, height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_labels(ax, typ, spacing=5):\n",
    "    #This function add the labels in the bar and line plots\n",
    "    #input the ax to add the labels, the type of plot\n",
    "    \n",
    "    space = spacing\n",
    "    va = 'bottom'\n",
    "    \n",
    "\n",
    "    if typ == 'bar':\n",
    "        for i in ax.patches:\n",
    "            y_value = i.get_height()\n",
    "            x_value = i.get_x() + i.get_width() / 2\n",
    "\n",
    "            label = \"{:.2f}\".format(y_value)\n",
    "            ax.annotate(label,(x_value, y_value), xytext=(0, space), \n",
    "                    textcoords=\"offset points\", ha='center', va=va, fontsize=10)     \n",
    "\n",
    "    if typ == 'line':\n",
    "        for line in ax.lines:\n",
    "            for x_value, y_value in zip(line.get_xdata(), line.get_ydata()):\n",
    "                label = \"{:.2f}\".format(y_value)\n",
    "                ax.annotate(label,(x_value, y_value), xytext=(0, space), \n",
    "                    textcoords=\"offset points\", ha='center', va=va, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\ssai\\OneDrive\\Data_26-07\\labs\\Lab-Customer-Analysis-round-7\\lab-customer-analysis-round-7\\files_for_lab\\csv_files/marketing_customer_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures()\n",
    "use_poly = False\n",
    "reg =  LinearRegression()                #initialization of the method\n",
    "numerical_transformer = StandardScaler() #initialization of the method\n",
    "split_feature = 'total_claim_amount'     # choose feature to split\n",
    "train_test_split_ratio = 0.2             # ratio for train and test split\n",
    "outlier = ['number_of_policies']         # columns to be cleaned of outliers\n",
    "\n",
    "# list of features/columns that have low coefficient values for the Standard model and will be dropped\n",
    "drop_columns = ['customer', 'effective_to_date', 'sales_channel', 'state', 'education', 'number_of_open_complaints'\n",
    "               , 'months_since_policy_inception', 'vehicle_size', 'policy',\n",
    "                'months_since_last_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.lower()             # transform all column names to lower case\n",
    "data.columns = data.columns.str.replace(' ','_')    # repalce spaces inbetween with '_'\n",
    "\n",
    "Q1 = data.quantile(0.25) # first quantile\n",
    "Q3 = data.quantile(0.75) # third quantile\n",
    "IQR = Q3 - Q1            # inter quantile range\n",
    "\n",
    "data = data[~(                     # negation so we get the datapoints within the whiskers\n",
    "(data[outlier] < (Q1 - 1.5 * IQR)) # datapoints left of the \"left whisker\"\n",
    "|(data[outlier] > (Q3 + 1.5 * IQR) # datapoints right of the 'right whisker'\n",
    ")).any(axis=1)]\n",
    "\n",
    "data = data.drop(columns=drop_columns) # dropping low impact columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns.drop(split_feature)] # features\n",
    "y = data[split_feature]                    # target feature\n",
    "x = pd.get_dummies(x, drop_first = True)   # dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = train_test_split_ratio, random_state = 42) # train test split\n",
    "\n",
    "if use_poly:\n",
    "    X_train = poly.fit_transform(X_train) # fit and transform X_train with PolynomialFeatures\n",
    "    X_test = poly.transform(X_test)       # transformX_test with PolynomialFeatures\n",
    "else:\n",
    "    X_train = numerical_transformer.fit_transform(X_train) # fit and transform X_train\n",
    "    X_test = numerical_transformer.transform(X_test)       # transformX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train) # train on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = reg.predict(X_train) # create predictions for our train data\n",
    "predictions_test = reg.predict(X_test)   # create predictions for our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 value for train: 0.7696091117258597\n",
      "R2 value for test: 0.7716572809167026\n"
     ]
    }
   ],
   "source": [
    "r2_train = r2_score(y_train, predictions_train) # calculate r2 score for train data\n",
    "r2_test = r2_score(y_test, predictions_test)    # calculate r2 score for test data\n",
    "\n",
    "print('R2 value for train: {}'.format(r2_train))\n",
    "print('R2 value for test: {}'.format(r2_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe scores from previous attempts in a dictionary\n",
    "rms = {'Model used' : ['LinearRegression', 'HuberRegressor', 'RANSACRegressor', 'ElasticNet', \n",
    "                       'SGDRegressor', 'BayesianRidge', 'SVR', 'KernelRidge', 'GradientBoostingRegressor'],\n",
    "    'Train score' : [0.77, 0.75, 0.66, 0.66, 0.76, 0.76, 0.31, -1.4, 0.86],\n",
    "    'Test score' : [0.77, 0.73, 0.67, 0.68, 0.74, 0.74, 0.32, -1.5, 0.82],\n",
    "    'Train score using PolynomialFeatures' : [0.86, -0.25, 0.42, 0.84, -3, 0.83, 0.08, 0.59, 0.88],\n",
    "    'Test scote using PolynomialFeatures' : [0.80, -0.25, 0.42, 0.82, -3, 0.81, 0.09, 0.46, 0.82],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model used</th>\n",
       "      <th>Train score</th>\n",
       "      <th>Test score</th>\n",
       "      <th>Train score using PolynomialFeatures</th>\n",
       "      <th>Test scote using PolynomialFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model used  Train score  Test score  \\\n",
       "0           LinearRegression         0.77        0.77   \n",
       "1             HuberRegressor         0.75        0.73   \n",
       "2            RANSACRegressor         0.66        0.67   \n",
       "3                 ElasticNet         0.66        0.68   \n",
       "4               SGDRegressor         0.76        0.74   \n",
       "5              BayesianRidge         0.76        0.74   \n",
       "6                        SVR         0.31        0.32   \n",
       "7                KernelRidge        -1.40       -1.50   \n",
       "8  GradientBoostingRegressor         0.86        0.82   \n",
       "\n",
       "   Train score using PolynomialFeatures  Test scote using PolynomialFeatures  \n",
       "0                                  0.86                                 0.80  \n",
       "1                                 -0.25                                -0.25  \n",
       "2                                  0.42                                 0.42  \n",
       "3                                  0.84                                 0.82  \n",
       "4                                 -3.00                                -3.00  \n",
       "5                                  0.83                                 0.81  \n",
       "6                                  0.08                                 0.09  \n",
       "7                                  0.59                                 0.46  \n",
       "8                                  0.88                                 0.82  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model_scores = pd.DataFrame(data=rms)\n",
    "regression_model_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclussion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best scores are obtained with GradienBoostingREgressor with PolynomialFeatures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
